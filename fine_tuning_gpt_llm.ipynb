{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "project_folder = Path('/content/drive/My Drive/cs229-audio-project/fine_tuning_llm/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Jzr4cZRnl3",
        "outputId": "c3ff58e5-ce36-46f1-eb90-f106b30b1a9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_input = pd.read_csv(project_folder / 'data_triplets_after_llm_latex_2024-03-16_02-43-06.csv')\n",
        "display(data_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "_J_aw85TSLXO",
        "outputId": "5ead467d-ac62-4eee-9c03-836adbaf2ac7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            Spoken Text  Formula ID  \\\n",
              "0                               The rank of a matrix A.           1   \n",
              "1                      The nullity of a given matrix A.           2   \n",
              "2     P of z equals three hundred fourteen plus one ...           3   \n",
              "3     Force vector equals mass times acceleration ve...           4   \n",
              "4     Energy equals mass times the speed of light sq...           5   \n",
              "...                                                 ...         ...   \n",
              "2461  The cross product of the vectors with componen...         818   \n",
              "2462  The cross product of the vectors with componen...         819   \n",
              "2463  The cross product of the vectors with componen...         820   \n",
              "2464  The cross product of the vectors with componen...         821   \n",
              "2465  The cross product of the vectors with componen...         822   \n",
              "\n",
              "                                             Latex  \\\n",
              "0                                 \\text{{Rank}}(A)   \n",
              "1                              \\text{{Nullity}}(A)   \n",
              "2     p(z) = 314 + 122v + 355b^2 + \\cdots + 444b^n   \n",
              "3                          \\vec{F} = m\\vec{\\alpha}   \n",
              "4                                       E = m{c}^2   \n",
              "...                                            ...   \n",
              "2461            [106,800,213] \\times [450,206,869]   \n",
              "2462           [890,879,829] \\times [3381,338,180]   \n",
              "2463             [336,739,485] \\times [160,546,86]   \n",
              "2464             [52,837,748] \\times [845,748,168]   \n",
              "2465                [617,395,564] \\times [69,6,64]   \n",
              "\n",
              "                                             Audio Path  Spoken Text Version  \\\n",
              "0     /content/drive/My Drive/cs229-audio-project/au...                    1   \n",
              "1     /content/drive/My Drive/cs229-audio-project/au...                    1   \n",
              "2     /content/drive/My Drive/cs229-audio-project/au...                    1   \n",
              "3     /content/drive/My Drive/cs229-audio-project/au...                    1   \n",
              "4     /content/drive/My Drive/cs229-audio-project/au...                    1   \n",
              "...                                                 ...                  ...   \n",
              "2461  /content/drive/My Drive/cs229-audio-project/au...                    3   \n",
              "2462  /content/drive/My Drive/cs229-audio-project/au...                    3   \n",
              "2463  /content/drive/My Drive/cs229-audio-project/au...                    3   \n",
              "2464  /content/drive/My Drive/cs229-audio-project/au...                    3   \n",
              "2465  /content/drive/My Drive/cs229-audio-project/au...                    3   \n",
              "\n",
              "                                       Transcribed Text  \\\n",
              "0                                The rank of a matrix A   \n",
              "1                      the nullity of a given matrix A.   \n",
              "2     p of variable equals number plus number times ...   \n",
              "3     Force vector equals mass times acceleration ve...   \n",
              "4        E equals mass times the speed of light squared   \n",
              "...                                                 ...   \n",
              "2461  The cross product of the vectors with componen...   \n",
              "2462  The cross product of the vectors with componen...   \n",
              "2463  The cross product of the vectors with componen...   \n",
              "2464  The cross product of the vectors with componen...   \n",
              "2465  The cross product of the vectors with componen...   \n",
              "\n",
              "                                    LLM Predicted Latex  \n",
              "0                                        \\text{rank}(A)  \n",
              "1                                     \\text{Nullity}(A)  \n",
              "2          p(x) = a_0 + a_1x + a_2x^2 + \\ldots + a_nx^n  \n",
              "3                                   \\vec{F} = m \\vec{a}  \n",
              "4                                       E = m \\cdot c^2  \n",
              "...                                                 ...  \n",
              "2461  \\begin{equation}\\n\\mathbf{v_1} = \\begin{bmatri...  \n",
              "2462  \\mathbf{v} = \\begin{pmatrix} 890 \\\\ 879 \\\\ 829...  \n",
              "2463  \\begin{equation}\\n\\begin{pmatrix}\\n336 \\\\\\n739...  \n",
              "2464  \\[\\n\\begin{vmatrix}\\n\\mathbf{i} & \\mathbf{j} &...  \n",
              "2465  \\vec{v} = \\begin{bmatrix} 617 \\\\ 395 \\\\ 564 \\e...  \n",
              "\n",
              "[2466 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ed7a2a-b899-4576-b27b-b09196d6deb7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spoken Text</th>\n",
              "      <th>Formula ID</th>\n",
              "      <th>Latex</th>\n",
              "      <th>Audio Path</th>\n",
              "      <th>Spoken Text Version</th>\n",
              "      <th>Transcribed Text</th>\n",
              "      <th>LLM Predicted Latex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The rank of a matrix A.</td>\n",
              "      <td>1</td>\n",
              "      <td>\\text{{Rank}}(A)</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>1</td>\n",
              "      <td>The rank of a matrix A</td>\n",
              "      <td>\\text{rank}(A)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The nullity of a given matrix A.</td>\n",
              "      <td>2</td>\n",
              "      <td>\\text{{Nullity}}(A)</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>1</td>\n",
              "      <td>the nullity of a given matrix A.</td>\n",
              "      <td>\\text{Nullity}(A)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P of z equals three hundred fourteen plus one ...</td>\n",
              "      <td>3</td>\n",
              "      <td>p(z) = 314 + 122v + 355b^2 + \\cdots + 444b^n</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>1</td>\n",
              "      <td>p of variable equals number plus number times ...</td>\n",
              "      <td>p(x) = a_0 + a_1x + a_2x^2 + \\ldots + a_nx^n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Force vector equals mass times acceleration ve...</td>\n",
              "      <td>4</td>\n",
              "      <td>\\vec{F} = m\\vec{\\alpha}</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>1</td>\n",
              "      <td>Force vector equals mass times acceleration ve...</td>\n",
              "      <td>\\vec{F} = m \\vec{a}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Energy equals mass times the speed of light sq...</td>\n",
              "      <td>5</td>\n",
              "      <td>E = m{c}^2</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>1</td>\n",
              "      <td>E equals mass times the speed of light squared</td>\n",
              "      <td>E = m \\cdot c^2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461</th>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>818</td>\n",
              "      <td>[106,800,213] \\times [450,206,869]</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>3</td>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>\\begin{equation}\\n\\mathbf{v_1} = \\begin{bmatri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2462</th>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>819</td>\n",
              "      <td>[890,879,829] \\times [3381,338,180]</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>3</td>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>\\mathbf{v} = \\begin{pmatrix} 890 \\\\ 879 \\\\ 829...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2463</th>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>820</td>\n",
              "      <td>[336,739,485] \\times [160,546,86]</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>3</td>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>\\begin{equation}\\n\\begin{pmatrix}\\n336 \\\\\\n739...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2464</th>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>821</td>\n",
              "      <td>[52,837,748] \\times [845,748,168]</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>3</td>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>\\[\\n\\begin{vmatrix}\\n\\mathbf{i} &amp; \\mathbf{j} &amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>822</td>\n",
              "      <td>[617,395,564] \\times [69,6,64]</td>\n",
              "      <td>/content/drive/My Drive/cs229-audio-project/au...</td>\n",
              "      <td>3</td>\n",
              "      <td>The cross product of the vectors with componen...</td>\n",
              "      <td>\\vec{v} = \\begin{bmatrix} 617 \\\\ 395 \\\\ 564 \\e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2466 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ed7a2a-b899-4576-b27b-b09196d6deb7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0ed7a2a-b899-4576-b27b-b09196d6deb7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0ed7a2a-b899-4576-b27b-b09196d6deb7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5785f1d5-86bd-4b68-be63-73a3a7808da0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5785f1d5-86bd-4b68-be63-73a3a7808da0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5785f1d5-86bd-4b68-be63-73a3a7808da0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_input",
              "summary": "{\n  \"name\": \"data_input\",\n  \"rows\": 2466,\n  \"fields\": [\n    {\n      \"column\": \"Spoken Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2361,\n        \"samples\": [\n          \"The inverse of g applied to z.\",\n          \"Add the cosine of epsilon to the sine of epsilon.\",\n          \"The sum of 552 and 616 is forty-seven.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Formula ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 237,\n        \"min\": 1,\n        \"max\": 822,\n        \"num_unique_values\": 822,\n        \"samples\": [\n          611,\n          175,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 807,\n        \"samples\": [\n          \"\\\\langle c, z \\\\rangle = c \\\\cdot \\\\delta\",\n          \"b_1, z_2,..., a_n \\\\in \\\\mathbb{Y}\",\n          \"\\\\det(C) = 4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Audio Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2466,\n        \"samples\": [\n          \"/content/drive/My Drive/cs229-audio-project/audiodb_new_simple_eqs/audios/v2_f257.mp3\",\n          \"/content/drive/My Drive/cs229-audio-project/audiodb_new_simple_eqs/audios/v2_f460.mp3\",\n          \"/content/drive/My Drive/cs229-audio-project/audiodb_new_simple_eqs/audios/v1_f622.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spoken Text Version\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcribed Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2337,\n        \"samples\": [\n          \"V to the power of 2 plus \\u0394 to the power of 2 equals \\u03b2 to the power of 2\",\n          \"The tensor product of zeta and zeta gives us a\",\n          \"Y is mapped to X.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LLM Predicted Latex\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2217,\n        \"samples\": [\n          \"e^{i \\\\pi} + 681 = 0\",\n          \"\\\\text{det}(A) = 713\",\n          \"\\\\log_{\\\\text{base}} C = 665\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def backup_df(df, prefix, folder_path):\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "    file_path = folder_path / f\"{prefix}_{current_time}.csv\"\n",
        "    df.to_csv(file_path, index=False)\n",
        "\n",
        "    print(f\"DataFrame saved to: {file_path}\")"
      ],
      "metadata": {
        "id": "N2gQztuSS8Cg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLyqQEP_Vn-O",
        "outputId": "fab881fc-016b-4287-e916-8e5228e6783d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_message(english_of_equation, desired_latex_response):\n",
        "\n",
        "    # purposely missing space since that's the way the inference is doing it (small bug)\n",
        "    preprompt = \"take this transcription and write the equation in latex.Don't allow any english and use only latex.\"\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\" : preprompt},\n",
        "            {\"role\": \"user\", \"content\" : english_of_equation},\n",
        "            {\"role\": \"assistant\", \"content\": desired_latex_response}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "def make_messages(triplets_df):\n",
        "    return triplets_df.apply(lambda row: make_message(row[\"Spoken Text\"], row[\"Latex\"]), axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_test_dataset_from_input_data(triplets_df):\n",
        "    \"\"\"\n",
        "    opein ai example:\n",
        "\n",
        "    {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
        "    {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
        "    {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
        "    \"\"\"\n",
        "    # train_df, test_df = train_test_split(triplets_df, test_size=test_ratio, random_state=42)\n",
        "    train_size = 50\n",
        "    valid_size = 25\n",
        "    train_df, valid_df, test_df = triplets_df[:train_size], triplets_df[train_size:train_size+valid_size], triplets_df[train_size+valid_size:]\n",
        "\n",
        "\n",
        "    training_dataset = list(make_messages(train_df).to_dict().values())\n",
        "    test_dataset = list(make_messages(test_df).to_dict().values())\n",
        "    valid_dataset = list(make_messages(valid_df).to_dict().values())\n",
        "    return training_dataset, valid_dataset, test_dataset"
      ],
      "metadata": {
        "id": "GAwkiYY5S_fc"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total=\", len(data_input))\n",
        "data_input = data_input.dropna()\n",
        "train, valid, test = train_test_dataset_from_input_data(data_input)\n",
        "print(\"train=\", len(train))\n",
        "print(\"valid=\", len(valid))\n",
        "print(\"test=\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBiEBW-taUXP",
        "outputId": "08d7c096-8d25-4bed-c00b-3ecb25fe8bab"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total= 2461\n",
            "train= 50\n",
            "valid= 25\n",
            "test= 2386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxUsigovObqF",
        "outputId": "51464224-bc96-425d-c8f9-efd0a58bafa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset name = train ----------------------------------------------------------------------------------------------------\n",
            "No errors found\n",
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 50, 117\n",
            "mean / median: 68.08, 56.0\n",
            "p5 / p95: 50.0, 94.70000000000002\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 7, 39\n",
            "mean / median: 14.54, 10.5\n",
            "p5 / p95: 7.0, 26.1\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
            "Dataset has ~3404 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~10212 tokens\n",
            "dataset name = test ----------------------------------------------------------------------------------------------------\n",
            "No errors found\n",
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 43, 127\n",
            "mean / median: 65.24476110645432, 61.0\n",
            "p5 / p95: 52.0, 87.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 4, 48\n",
            "mean / median: 14.306789606035206, 12.0\n",
            "p5 / p95: 7.0, 26.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
            "Dataset has ~155674 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~467022 tokens\n",
            "dataset name = valid ----------------------------------------------------------------------------------------------------\n",
            "No errors found\n",
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 50, 53\n",
            "mean / median: 50.8, 50.0\n",
            "p5 / p95: 50.0, 53.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 7, 8\n",
            "mean / median: 7.4, 7.0\n",
            "p5 / p95: 7.0, 8.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
            "Dataset has ~1270 tokens that will be charged for during training\n",
            "By default, you'll train for 4 epochs on this dataset\n",
            "By default, you'll be charged for ~5080 tokens\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "for to_verify in ((\"train\", train), (\"test\", test), (\"valid\", valid)):\n",
        "    name, dataset = to_verify\n",
        "    print(\"dataset name =\", name, \"-\"*100)\n",
        "\n",
        "    # Format error checks\n",
        "    format_errors = defaultdict(int)\n",
        "\n",
        "    for ex in dataset:\n",
        "        if not isinstance(ex, dict):\n",
        "            format_errors[\"data_type\"] += 1\n",
        "            continue\n",
        "\n",
        "        messages = ex.get(\"messages\", None)\n",
        "        if not messages:\n",
        "            format_errors[\"missing_messages_list\"] += 1\n",
        "            continue\n",
        "\n",
        "        for message in messages:\n",
        "            if \"role\" not in message or \"content\" not in message:\n",
        "                format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "                format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "                format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "            content = message.get(\"content\", None)\n",
        "            function_call = message.get(\"function_call\", None)\n",
        "\n",
        "            if (not content and not function_call) or not isinstance(content, str):\n",
        "                format_errors[\"missing_content\"] += 1\n",
        "\n",
        "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "            format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "    if format_errors:\n",
        "        print(\"Found errors:\")\n",
        "        for k, v in format_errors.items():\n",
        "            print(f\"{k}: {v}\")\n",
        "    else:\n",
        "        print(\"No errors found\")\n",
        "\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    # not exact!\n",
        "    # simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "    def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "        num_tokens = 0\n",
        "        for message in messages:\n",
        "            num_tokens += tokens_per_message\n",
        "            for key, value in message.items():\n",
        "                num_tokens += len(encoding.encode(value))\n",
        "                if key == \"name\":\n",
        "                    num_tokens += tokens_per_name\n",
        "        num_tokens += 3\n",
        "        return num_tokens\n",
        "\n",
        "    def num_assistant_tokens_from_messages(messages):\n",
        "        num_tokens = 0\n",
        "        for message in messages:\n",
        "            if message[\"role\"] == \"assistant\":\n",
        "                num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "        return num_tokens\n",
        "\n",
        "    def print_distribution(values, name):\n",
        "        print(f\"\\n#### Distribution of {name}:\")\n",
        "        print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "        print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "        print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "    # Warnings and tokens counts\n",
        "    n_missing_system = 0\n",
        "    n_missing_user = 0\n",
        "    n_messages = []\n",
        "    convo_lens = []\n",
        "    assistant_message_lens = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        messages = ex[\"messages\"]\n",
        "        if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "            n_missing_system += 1\n",
        "        if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "            n_missing_user += 1\n",
        "        n_messages.append(len(messages))\n",
        "        convo_lens.append(num_tokens_from_messages(messages))\n",
        "        assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "    print(\"Num examples missing system message:\", n_missing_system)\n",
        "    print(\"Num examples missing user message:\", n_missing_user)\n",
        "    print_distribution(n_messages, \"num_messages_per_example\")\n",
        "    print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "    print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "    n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "    print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
        "\n",
        "    # Pricing and default n_epochs estimate\n",
        "    MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "    TARGET_EPOCHS = 3\n",
        "    MIN_TARGET_EXAMPLES = 100\n",
        "    MAX_TARGET_EXAMPLES = 25000\n",
        "    MIN_DEFAULT_EPOCHS = 1\n",
        "    MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "    n_epochs = TARGET_EPOCHS\n",
        "    n_train_examples = len(dataset)\n",
        "    if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "        n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "    elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "        n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "    n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "    print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "    print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "    print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_jsonl(data, filename):\n",
        "    \"\"\"\n",
        "    Write a list of dictionaries to a JSON Lines file.\n",
        "\n",
        "    Args:\n",
        "    - data (list): List of dictionaries to write to the file.\n",
        "    - filename (str): Name of the output JSON Lines file.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as file:\n",
        "        for item in data:\n",
        "            json.dump(item, file)\n",
        "            file.write('\\n')\n",
        "\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "train_jsonl_path = project_folder / f\"train_data_{current_time}.jsonl\"\n",
        "validation_jsonl_path = project_folder / f\"validation_data_{current_time}.jsonl\"\n",
        "test_jsonl_path = project_folder / f\"test_data_{current_time}.jsonl\"\n",
        "\n",
        "write_jsonl(train, train_jsonl_path)\n",
        "write_jsonl(valid, validation_jsonl_path)\n",
        "write_jsonl(test, test_jsonl_path)\n",
        "print(\"done.\")\n",
        "print(\"Wrote to\", train_jsonl_path, \"\\n and\", test_jsonl_path, \"\\n and\", validation_jsonl_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2QT_HnVcmPV",
        "outputId": "33ce6d94-2a32-4a99-e35e-54525c887efc"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n",
            "Wrote to /content/drive/My Drive/cs229-audio-project/fine_tuning_llm/train_data_2024-03-16_05-27-40.jsonl \n",
            " and /content/drive/My Drive/cs229-audio-project/fine_tuning_llm/test_data_2024-03-16_05-27-40.jsonl \n",
            " and /content/drive/My Drive/cs229-audio-project/fine_tuning_llm/validation_data_2024-03-16_05-27-40.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLzKfhFjbp0y",
        "outputId": "c1c95a4a-44c1-429e-9a40-1c96ab1ece88"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "lYtl6DWPbmDs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file = client.files.create(\n",
        "#   file=open(train_jsonl_path, \"rb\"),\n",
        "#   purpose=\"fine-tune\"\n",
        "# )"
      ],
      "metadata": {
        "id": "_z7aptQocdTu"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(file.id)\n",
        "# client.fine_tuning.jobs.create(\n",
        "#   training_file=file.id,\n",
        "#   model=\"gpt-3.5-turbo\"\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW0z3QjTfOrM",
        "outputId": "247c0290-9759-4e3f-b221-77ef1246fe1f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file-UX2OXldVtNzF8EffFgjbaavM\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-IFDMxYSyvH3YRdgcA5wGiyZ6', created_at=1710565021, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vt5vDvT6zTCqmBJzGnq1MVZM', result_files=[], status='validating_files', trained_tokens=None, training_file='file-UX2OXldVtNzF8EffFgjbaavM', validation_file=None, user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finetune_job_file = file.id"
      ],
      "metadata": {
        "id": "QraEMN6sfh98"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD5qxtTJsMmt",
        "outputId": "2564666e-6e6d-4a8a-c70b-745eccd9312d"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-Aw7IazQGaVnx9pCIm18LY9ie', created_at=1710566954, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-vt5vDvT6zTCqmBJzGnq1MVZM', result_files=[], status='running', trained_tokens=None, training_file='file-1orpuySX09efOFwnq0T6VJiZ', validation_file='file-HOrfM5JKI3oxYAM9lB7xKcsL', user_provided_suffix='latexer'), FineTuningJob(id='ftjob-IFDMxYSyvH3YRdgcA5wGiyZ6', created_at=1710565021, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vt5vDvT6zTCqmBJzGnq1MVZM', result_files=[], status='cancelled', trained_tokens=None, training_file='file-UX2OXldVtNzF8EffFgjbaavM', validation_file=None, user_provided_suffix=None), FineTuningJob(id='ftjob-8sKIL3rMCGzLghiotOT847Gx', created_at=1710564681, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vt5vDvT6zTCqmBJzGnq1MVZM', result_files=[], status='cancelled', trained_tokens=None, training_file='file-6zm6rc5nS37yq7LDu6x8j2rt', validation_file=None, user_provided_suffix=None), FineTuningJob(id='ftjob-nxARJZvhK4ZhCzt7JctplBa0', created_at=1710563047, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vt5vDvT6zTCqmBJzGnq1MVZM', result_files=[], status='cancelled', trained_tokens=None, training_file='file-hCzg4EJdWCfmm7IDRksrj7in', validation_file=None, user_provided_suffix=None), FineTuningJob(id='ftjob-8vYKN5sMOOw2urpUIV8iky5F', created_at=1710562822, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vt5vDvT6zTCqmBJzGnq1MVZM', result_files=[], status='cancelled', trained_tokens=None, training_file='file-hDQShDM5RD4g9bJbba71KPGP', validation_file=None, user_provided_suffix=None)], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pprint\n",
        "\n",
        "# def get_fine_tune_status(fdjob_str):\n",
        "#     # List 10 fine-tuning jobs\n",
        "#     pprint.pprint(client.fine_tuning.jobs.list(limit=10))\n",
        "\n",
        "#     # Retrieve the state of a fine-tune\n",
        "#     pprint.pprint(client.fine_tuning.jobs.retrieve(fdjob_str))\n",
        "\n",
        "#     # # Cancel a job\n",
        "#     # client.fine_tuning.jobs.cancel(fdjob_str)\n",
        "\n",
        "#     # List up to 10 events from a fine-tuning job\n",
        "#     pprint.pprint(client.fine_tuning.jobs.list_events(fine_tuning_job_id=fdjob_str, limit=10))\n",
        "\n",
        "#     # # Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
        "#     # client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")\n",
        "\n",
        "# get_fine_tune_status(\"ftjob-IFDMxYSyvH3YRdgcA5wGiyZ6\") # is the fine tuning job id (printed in funciton above when listing)"
      ],
      "metadata": {
        "id": "5kkAbI5nfoEQ"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MgSgJfTmnZg",
        "outputId": "cb81205d-e125-47e3-a012-7737221e293b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-6zm6rc5nS37yq7LDu6x8j2rt', bytes=109486, created_at=1710564678, filename='train_data_2024-03-16_04-51-07.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_last_events(fdjob_str):\n",
        "    response = client.fine_tuning.jobs.list_events(fdjob_str)\n",
        "\n",
        "    events = response.data\n",
        "    events.reverse()\n",
        "\n",
        "    for event in events:\n",
        "        # print(event)\n",
        "        print(event.created_at, event.message, event)\n",
        "\n",
        "\n",
        "\n",
        "print_last_events(\"ftjob-Aw7IazQGaVnx9pCIm18LY9ie\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVijc3Hgjbsc",
        "outputId": "9bf5b34e-c486-47eb-c08e-79dc797f586b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1710566954 Created fine-tuning job: ftjob-Aw7IazQGaVnx9pCIm18LY9ie FineTuningJobEvent(id='ftevent-sGLDzAba6WmoyMkF9QIkgq7g', created_at=1710566954, level='info', message='Created fine-tuning job: ftjob-Aw7IazQGaVnx9pCIm18LY9ie', object='fine_tuning.job.event', data={}, type='message')\n",
            "1710566954 Validating training file: file-1orpuySX09efOFwnq0T6VJiZ and validation file: file-HOrfM5JKI3oxYAM9lB7xKcsL FineTuningJobEvent(id='ftevent-5JbSTdtu9rkd4YoDvFNDsRmY', created_at=1710566954, level='info', message='Validating training file: file-1orpuySX09efOFwnq0T6VJiZ and validation file: file-HOrfM5JKI3oxYAM9lB7xKcsL', object='fine_tuning.job.event', data={}, type='message')\n",
            "1710566976 Files validated, moving job to queued state FineTuningJobEvent(id='ftevent-Kw1g9uH7C3xdV65vo0vz76kD', created_at=1710566976, level='info', message='Files validated, moving job to queued state', object='fine_tuning.job.event', data={}, type='message')\n",
            "1710566977 Fine-tuning job started FineTuningJobEvent(id='ftevent-DfeVuJ942aU4feX7pRJxr4cX', created_at=1710566977, level='info', message='Fine-tuning job started', object='fine_tuning.job.event', data=None, type='message')\n",
            "1710567062 Step 1/150: training loss=2.13, validation loss=3.80 FineTuningJobEvent(id='ftevent-Dw1KzpbaIv6EIQjDQSY4gFPk', created_at=1710567062, level='info', message='Step 1/150: training loss=2.13, validation loss=3.80', object='fine_tuning.job.event', data={'step': 1, 'train_loss': 2.129176616668701, 'valid_loss': 3.8013671239217124, 'total_steps': 150, 'train_mean_token_accuracy': 0.7200000286102295, 'valid_mean_token_accuracy': 0.4444444444444444}, type='metrics')\n",
            "1710567080 Step 11/150: training loss=0.32, validation loss=2.94 FineTuningJobEvent(id='ftevent-Q8EKenjAQs3mqlTgbswtYcao', created_at=1710567080, level='info', message='Step 11/150: training loss=0.32, validation loss=2.94', object='fine_tuning.job.event', data={'step': 11, 'train_loss': 0.3151126503944397, 'valid_loss': 2.9419227176242404, 'total_steps': 150, 'train_mean_token_accuracy': 0.9259259104728699, 'valid_mean_token_accuracy': 0.5555555555555556}, type='metrics')\n",
            "1710567100 Step 21/150: training loss=1.50, validation loss=4.47 FineTuningJobEvent(id='ftevent-k9VbwN0Pac6oGnnJ99eB6TGt', created_at=1710567100, level='info', message='Step 21/150: training loss=1.50, validation loss=4.47', object='fine_tuning.job.event', data={'step': 21, 'train_loss': 1.5018253326416016, 'valid_loss': 4.473981761932373, 'total_steps': 150, 'train_mean_token_accuracy': 0.8235294222831726, 'valid_mean_token_accuracy': 0.4}, type='metrics')\n",
            "1710567121 Step 31/150: training loss=1.84, validation loss=2.27 FineTuningJobEvent(id='ftevent-3g4cMTg30SwpEGTTMCX6UCo3', created_at=1710567121, level='info', message='Step 31/150: training loss=1.84, validation loss=2.27', object='fine_tuning.job.event', data={'step': 31, 'train_loss': 1.8447273969650269, 'valid_loss': 2.2680124706692166, 'total_steps': 150, 'train_mean_token_accuracy': 0.8888888955116272, 'valid_mean_token_accuracy': 0.5555555555555556}, type='metrics')\n",
            "1710567141 Step 41/150: training loss=0.22, validation loss=2.79 FineTuningJobEvent(id='ftevent-zpHqUfvK2pclLNtEnJaZSHdL', created_at=1710567141, level='info', message='Step 41/150: training loss=0.22, validation loss=2.79', object='fine_tuning.job.event', data={'step': 41, 'train_loss': 0.2240377813577652, 'valid_loss': 2.7883361180623374, 'total_steps': 150, 'train_mean_token_accuracy': 0.8799999952316284, 'valid_mean_token_accuracy': 0.5555555555555556}, type='metrics')\n",
            "1710567159 Step 51/150: training loss=1.69, validation loss=2.15 FineTuningJobEvent(id='ftevent-mifLOFYkVLi8JvRvcMckXeif', created_at=1710567159, level='info', message='Step 51/150: training loss=1.69, validation loss=2.15', object='fine_tuning.job.event', data={'step': 51, 'train_loss': 1.6883283853530884, 'valid_loss': 2.1527505450778537, 'total_steps': 150, 'train_mean_token_accuracy': 0.8888888955116272, 'valid_mean_token_accuracy': 0.5555555555555556}, type='metrics')\n",
            "1710567179 Step 61/150: training loss=0.11, validation loss=1.35 FineTuningJobEvent(id='ftevent-wWeogTM6zex7Y6uyySwHqMnr', created_at=1710567179, level='info', message='Step 61/150: training loss=0.11, validation loss=1.35', object='fine_tuning.job.event', data={'step': 61, 'train_loss': 0.10697918385267258, 'valid_loss': 1.3532532585991754, 'total_steps': 150, 'train_mean_token_accuracy': 0.9268292784690857, 'valid_mean_token_accuracy': 0.4444444444444444}, type='metrics')\n",
            "1710567199 Step 71/150: training loss=0.05, validation loss=1.62 FineTuningJobEvent(id='ftevent-Jyi1UzXmS1vPOglPGxd0zmMW', created_at=1710567199, level='info', message='Step 71/150: training loss=0.05, validation loss=1.62', object='fine_tuning.job.event', data={'step': 71, 'train_loss': 0.049757253378629684, 'valid_loss': 1.6167030334472656, 'total_steps': 150, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 0.5555555555555556}, type='metrics')\n",
            "1710567219 Step 81/150: training loss=0.08, validation loss=2.03 FineTuningJobEvent(id='ftevent-1LJMwSjOhGSzHii8a9rsaQfM', created_at=1710567219, level='info', message='Step 81/150: training loss=0.08, validation loss=2.03', object='fine_tuning.job.event', data={'step': 81, 'train_loss': 0.0799807757139206, 'valid_loss': 2.0321487850613065, 'total_steps': 150, 'train_mean_token_accuracy': 0.9599999785423279, 'valid_mean_token_accuracy': 0.5555555555555556}, type='metrics')\n"
          ]
        }
      ]
    }
  ]
}